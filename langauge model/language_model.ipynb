{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.symbols import ORTH\n",
    "from torchtext import data, datasets\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use CUDA: True\n"
     ]
    }
   ],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "print(\"Use CUDA:\", USE_CUDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bptt_len = 60\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_file = 'questions.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_tok = spacy.load('en')\n",
    "def spacy_tok(x):\n",
    "    return [tok.text for tok in lm_tok.tokenizer(x)]\n",
    "\n",
    "TEXT = data.ReversibleField(sequential=True, tokenize=spacy_tok,\n",
    "                                    lower=True, include_lengths=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_dataset = datasets.LanguageModelingDataset(questions_file, TEXT, newline_eos=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2196017/2196017 [04:27<00:00, 8221.95it/s]\n"
     ]
    }
   ],
   "source": [
    "vectors = \"glove.840B.300d\"\n",
    "TEXT.build_vocab(questions_dataset, vectors=vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterators\n",
    "bpttiter = data.BPTTIterator(questions_dataset, batch_size=batch_size, bptt_len=bptt_len, repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 60])\n",
      "torch.Size([32, 60])\n",
      "tensor([[   8,   21,    4,  ...,    7,   14,  400],\n",
      "        [1891,    2,   18,  ...,   14,  711,   49],\n",
      "        [   3,  338,   22,  ...,   10, 1263,    2],\n",
      "        ...,\n",
      "        [   3,  483,  997,  ...,    7,    6, 2134],\n",
      "        [   8,   21,    4,  ...,   16,    3,   86],\n",
      "        [  18,    9,   17,  ...,    9,   39,    8]], device='cuda:0')\n",
      "tensor([[  21,    4,    3,  ...,   14,  400,   85],\n",
      "        [   2,   18,    9,  ...,  711,   49,    2],\n",
      "        [ 338,   22,    6,  ..., 1263,    2,    4],\n",
      "        ...,\n",
      "        [ 483,  997,    2,  ...,    6, 2134,    2],\n",
      "        [  21,    4,    3,  ...,    3,   86, 2952],\n",
      "        [   9,   17,    3,  ...,   39,    8,   69]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for batch in bpttiter:\n",
    "    x, y = batch.text.transpose(0, 1).contiguous().to(device), \\\n",
    "                   batch.target.transpose(0, 1).contiguous().to(device)\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    print(x)\n",
    "    print(y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
